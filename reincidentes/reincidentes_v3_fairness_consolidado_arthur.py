# -*- coding: utf-8 -*-
"""aaaa-v3-fairness-consolidado-arthur.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UIaM3grOFvpbJhpMN3r7Y_Y1Bk23fOQm

**Universidade Federal do ABC**

Prof. Paulo Henrique Pisani

Arthur Henrique Fernandes

Testes feitos com bibliotecas do scikit learn sobre fairness
"""

import pandas as pd
import pylab
import numpy as np
from sklearn import linear_model
import sklearn.preprocessing as preprocessing
import sklearn.metrics as metrics
import matplotlib.pyplot as plt
from statsmodels.stats import proportion
import pydotplus
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
import numpy as np

from sklearn.model_selection import StratifiedKFold
from sklearn.naive_bayes import GaussianNB, CategoricalNB
from sklearn.preprocessing import OrdinalEncoder, LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score
from sklearn.metrics import f1_score, classification_report
from sklearn.model_selection import train_test_split
from statsmodels.stats.outliers_influence import variance_inflation_factor
from collections import Counter

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from math import ceil

pd.options.mode.chained_assignment = None
i_tex = 0

"""# Adult dataset"""

#http://cejfe.gencat.cat/web/.content/home/recerca/opendata/jjuvenil/reincidenciaJusticiaMenors/recidivismJuvenileJustice_variables_EN.pdf
#http://cejfe.gencat.cat/en/recerca/opendata/jjuvenil/reincidencia-justicia-menors/index.html
german_df_full = pd.read_excel('content/reincidenciaJusticiaMenors.xlsx')

german_df = german_df_full.copy(deep = True)
german_df.head(10)

"""Removendo atributos não utilizados"""

cols = list(german_df)
used_cols = cols[2:11]
used_cols.append(cols[-1])
used_cols

cols_dropped = [l for l in cols if l not in used_cols]
cols_dropped

german_df.drop(cols_dropped, axis = 1, inplace = True)
german_df.head(10)

german_df.columns = ['Sex_encoded',	'estranger',	'nacionalitat', 'nacionalitat_agrupat',	'edat_fet_agrupat',	'provincia',	'comarca',	'edat_fet',	'edat_final_programa',	'Target_encoded']
german_df

german_df['Target_encoded'] = (german_df['Target_encoded'] == 'Sí').astype(int)
german_df['Sex_encoded'] = (german_df['Sex_encoded'] == 'Home').astype(int)

for feature in german_df.columns:
  german_df[feature] = german_df[feature].fillna(0)

  if feature != 'Target_encoded' and feature != 'Sex_encoded':
    german_df[feature] = german_df[feature].astype(str)

german_df

"""### Função que transforma os atributos categóricos em numéricos, importante para os algoritmos de predição:"""

def encodeR(train, test):
  #display(train)

  le = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',
                                 unknown_value=-1)
  data_train = train
  data_test = test
  features = ['estranger',	'nacionalitat', 'nacionalitat_agrupat',	'edat_fet_agrupat',	'provincia',	'comarca',	'edat_fet',	'edat_final_programa']

  #for feature in features:
    #print(np.array(data_train[feature]))
  le.fit(data_train[features])

  encoded_train = le.transform(data_train[features])
  pd_data_train = pd.DataFrame(encoded_train, columns=features, index= data_train.index)
  #display(pd_data_train)

  for feature in features:
    data_train = data_train.drop(feature, axis = 1)
    data_train[feature + "_encoded"] = pd_data_train[feature]

  #display(data_train)
  encoded_test = le.transform(data_test[features])
  pd_data_test = pd.DataFrame(encoded_test, columns=features, index= data_test.index)

  for feature in features:
    data_test = data_test.drop(feature, axis = 1)
    data_test[feature + "_encoded"] = pd_data_test[feature]

  encoded_y_train = data_train["Target_encoded"]
  encoded_y_test = data_test["Target_encoded"]

  #display(data_train)
  #display(data_test)
  #display(encoded_y_train)
  #display(encoded_y_test)

  #print('\n\nDtypes:')
  #print(data_train.dtypes, data_test.dtypes, encoded_y_train.dtypes, encoded_y_test.dtypes)

  return data_train, data_test, encoded_y_train, encoded_y_test

"""## Carregando as funções de métricas

### Disparate Impact

https://nbviewer.org/github/srnghn/bias-mitigation-examples/blob/master/Bias%20Mitigation%20with%20Disparate%20Impact%20Remover.ipynb
"""

def calcProportionPositive(df, attribute, attribute_value, class_label, class_value):#calcProportionPositive(encoded_x_train, 'Sex_encoded', 1, 'Target_encoded', 1)
  #display(df)
  df[attribute] = df[attribute].astype(str).astype(int)
  #print("attribute_value = {}".format(attribute))
  details = df.apply(lambda x : True
              if x[attribute] == attribute_value else False, axis = 1) #homens

  #print(df[attribute])
  #display(details)
  # Count number of True in the series
  num_rows = len(details[details == True].index)
  group = df[df[attribute] == attribute_value].copy()
  #display(group)

  group_positive = group.apply(lambda x : True
              if x[class_label] == class_value else False, axis = 1) #>50k

  num_group_positive = len(group_positive[group_positive == True].index)


  try:
    positiveRate = num_group_positive/group.shape[0]
    return num_rows, positiveRate
  except:
    print("Divisão por zero")

"""### Precisão por classe"""

from sklearn.metrics import classification_report
#print(classification_report(y_test, y_pred))

"""### Acurácia por atributo"""

def attributeAccuracy(df, pred_column, true_column):
  dfDetailsPred = df.apply(lambda x : True
            if x[pred_column] == x[true_column] else False, axis = 1)
  num_rowsPred = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_rowsPred

def truePositive(df, pred_column, true_column):
  dfDetailsPred = df.apply(lambda x : True
            if x[pred_column] == x[true_column] and x[pred_column] == 1 else False, axis = 1)
  num_rowsPred = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_rowsPred

def trueNegative(df, pred_column, true_column):
  dfDetailsPred = df.apply(lambda x : True
            if x[pred_column] == x[true_column] and x[pred_column] == 0 else False, axis = 1)
  num_rowsPred = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_rowsPred

def attAccuracyFiltered(df, pred_column, true_column):
  dfDetailsPred = df.apply(lambda x : True
            if x[pred_column] == x[true_column] else False, axis = 1)
  num_rowsPred = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_rowsPred/df.shape[0]

"""### Acurácia por grupo"""

def accuracyByGroup(X_t, y_test, y_pred, sensitive_attribute, group_b, group_w):
  #matrix = confusion_matrix(y_test, y_pred)

  #ConfusionMatrixDisplay.from_predictions(y_test, y_pred)

  #plt.show()

  dfAttSens = X_t
  dfAttSens['true_class']= y_test
  dfAttSens['predicted'] = y_pred
  print(dfAttSens.columns)  

  dfAttSens = dfAttSens.drop(columns=['estranger_encoded', 'nacionalitat_encoded',
       'nacionalitat_agrupat_encoded', 'edat_fet_agrupat_encoded',
       'provincia_encoded', 'comarca_encoded', 'edat_fet_encoded',
       'edat_final_programa_encoded'])
  
  df_B = dfAttSens[dfAttSens.Sex_encoded == group_b]
  df_W = dfAttSens[dfAttSens.Sex_encoded == group_w]

  accuracy_B = attributeAccuracy(df_B, 'predicted', 'true_class')
  bTruePositive = truePositive(df_B, 'predicted', 'true_class')
  bTrueNegative = trueNegative(df_B, 'predicted', 'true_class')

  accuracy_W = attributeAccuracy(df_W, 'predicted', 'true_class')
  wTruePositive = truePositive(df_W, 'predicted', 'true_class')
  wTrueNegative = trueNegative(df_W, 'predicted', 'true_class')

  df_B_true = df_B[df_B.true_class == 1]
  df_B_false = df_B[df_B.true_class == 0]

  df_W_true = df_W[df_W.true_class == 1]
  df_W_false = df_W[df_W.true_class == 0]

  accuracy_B_true = attAccuracyFiltered(df_B_true, 'predicted', 'true_class')
  accuracy_B_false = attAccuracyFiltered(df_B_false, 'predicted', 'true_class')

  accuracy_W_true = attAccuracyFiltered(df_W_true, 'predicted', 'true_class')
  accuracy_W_false = attAccuracyFiltered(df_W_false, 'predicted', 'true_class')

  b_metrics = ["Desfavorecido", accuracy_B_true, accuracy_B_false, bTrueNegative, bTruePositive + bTrueNegative, accuracy_B/df_B.shape[0]]
  w_metrics = ["Favorecido", accuracy_W_true, accuracy_W_false, wTrueNegative, wTruePositive + wTrueNegative, accuracy_W/df_W.shape[0]]

  return b_metrics, w_metrics

  #print("Grupo desfavorecido (S = b):")
  #print("Acurácia b = {}\t VP b={}\t VN b={}\t VP + VN b = {}\t %Acurácia b = {}".format(accuracy_B, bTruePositive, bTrueNegative, bTruePositive + bTrueNegative, accuracy_B/df_B.shape[0]))
  #print("\nGrupo favorecido (S = w)")
  #print("Acurácia w = {}\t VP w={}\t VN w={}\t VP + VN w = {}\t %Acurácia w = {}".format(accuracy_W, wTruePositive, wTrueNegative, wTruePositive + wTrueNegative, accuracy_W/dfMen.shape[0]))

"""## Classificadores"""

import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier

lr = LogisticRegression(solver='lbfgs', max_iter=4000)
gnb = GaussianNB()
gnb_isotonic = CalibratedClassifierCV(gnb, cv=2, method="isotonic")
gnb_sigmoid = CalibratedClassifierCV(gnb, cv=2, method="sigmoid")
dt = DecisionTreeClassifier(random_state=0)

clf_list = [
    (lr, "Logistic"),
    (gnb, "Naive Bayes"),
    (gnb_isotonic, "Naive Bayes + Isotonic"),
    (gnb_sigmoid, "Naive Bayes + Sigmoid"),
    (dt, "Decision Tree Classifier")
]

"""## Métricas


"""

from collections import defaultdict

from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    brier_score_loss,
    log_loss,
    roc_auc_score,
)

"""# Pré processamento

## Massageamento

### Criando ranker
"""

def ranker(df, att_sens, target_class):
  from sklearn.naive_bayes import GaussianNB
  rank_x = df.drop("Target_encoded", axis = 1)
  rank_y = df["Target_encoded"]
  

  #X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=0)
  gnb = GaussianNB()
  y_pred = gnb.fit(rank_x, rank_y).predict(rank_x)
  probabilities_full = gnb.predict_proba(rank_x)
  
  promo = criaCandidatos(rank_x, rank_y, att_sens, 0, 0, probabilities_full)
  demo = criaCandidatos(rank_x, rank_y, att_sens, 1, 1, probabilities_full)
  return promo, demo  

def criaCandidatos(df_x, df_y, att_sens, att_value, target_class, prob_full):
  
  prob_class = []
  for x in prob_full:
    if target_class == 0:
      prob_class.append(x[0])
    else:
      prob_class.append(x[1])

  df_x['true_class'] = df_y
  df_x['predict_proba'] = prob_class

  #print(df_x)

  #checar se na coluna att_sens o valor do atributo é att_value
  #for row in df_x:
  #  if row[att_sens] == att_value:
  #    candidates.append(row)
  candidates = df_x.loc[(df_x[att_sens] == att_value) & (df_x['true_class'] == target_class)]

  return candidates

"""### Calculando a discriminação

M = (disc(D) x |grupo desfavorecido| x |grupo favorecido|) / |D|
"""

def massageChanges(df, sensitive_att, b_code, w_code, class_label, target_class):

  women, women_positive_rate = calcProportionPositive(df, sensitive_att, b_code, class_label, 1)
  men, men_positive_rate = calcProportionPositive(df, sensitive_att, w_code, class_label, 1)

  discD = men_positive_rate - women_positive_rate
  m = (discD * women * men) / df.shape[0]
  return m, discD

"""## Distribuição de pesos

1.  contar quantos X(S) = b e quantos X = +
2.  contar quantos X(S) = b e quantos desses são +
3.  multiplicar valores de 1. e 2.
4.  fazer o mesmo pra X(S) = w
"""

def attributeCount(df, att_column, att_value):
  dfDetailsPred = df.apply(lambda x : True
            if x[att_column] == att_value else False, axis = 1)
  num_objects = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_objects

def attributeTrue(df, att_column, att_value):
  dfDetailsPred = df.apply(lambda x : True
            if x[att_column] == att_value and x['Target_encoded'] == 1 else False, axis = 1)
  num_rowsPred = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_rowsPred

def attributeFalse(df, att_column, att_value):
  dfDetailsPred = df.apply(lambda x : True
            if x[att_column] == att_value and x['Target_encoded'] == 0 else False, axis = 1)
  num_rowsPred = len(dfDetailsPred[dfDetailsPred == True].index)

  return num_rowsPred

#total = adult_df_numerical.shape[0]
#n_true = attributeCount(adult_df_numerical, 'Target_Encoded', 1)
#n_false = attributeCount(adult_df_numerical, 'Target_Encoded', 0)

#n_women = attributeCount(adult_df_numerical, 'Sex_Encoded', 0)

#n_womenTrue = attributeTrue(adult_df_numerical, 'Sex_Encoded', 0)

#print(total, n_women, n_true, n_womenTrue)

#print(n_women/total, n_true/total , n_womenTrue/n_true)

#num = n_women/total * n_true/total
#den = n_womenTrue/n_true

#print("Peso do sex = f e class + :")
#print(num/den)

#n_men = attributeCount(adult_df_numerical, 'Sex_Encoded', 1)

#n_menTrue = attributeTrue(adult_df_numerical, 'Sex_Encoded', 1)

#print(total, n_men, n_true, n_menTrue)

#print(n_men/total, n_true/total , n_menTrue/n_true)

#num = n_men/total * n_true/total
#den = n_menTrue/n_true

#print("Peso do sex = m e class + :")
#print(num/den)

#n_womenFalse = attributeFalse(adult_df_numerical, 'Sex_Encoded', 0)

#print(total, n_women, n_false, n_womenFalse)

#print(n_women/total, n_false/total , n_womenFalse/n_false)

#num = n_women/total * n_false/total
#den = n_womenFalse/n_false

#print("Peso do sex = f e class - :")
#print(num/den)

#n_menFalse = attributeFalse(adult_df_numerical, 'Sex_Encoded', 1)

#print(total, n_men, n_false, n_menFalse)

#print(n_men/total, n_false/total , n_menFalse/n_false)

#num = n_men/total * n_false/total
#den = n_menFalse/n_false

#print("Peso do sex = m e class - :")
#print(num/den)

"""## Preferential Sampling"""

def ttSplit(df, attr, target_class, ts=0.10):
    """Train / Test split dataframe df with test proportion ts. Also get
    an additional train /test set with protected attribute reversed for counterfactual analysis."""
    
    from sklearn.model_selection import train_test_split

    train, test = train_test_split(df, test_size=ts)

    X_test = test.drop([target_class], axis=1).values
    y_test = test[target_class].values

    rtest = test.copy()
    ftest = test.copy()
    utest = test.copy()
    
    rtest[attr] = [0 if s == 1 else 1 for s in test[attr]]
    ftest[attr] = 1
    utest[attr] = 0
    
    rX_test = rtest.drop([target_class], axis=1).values
    ry_test = rtest[target_class].values
    fX_test = ftest.drop([target_class], axis=1).values
    fy_test = ftest[target_class].values
    uX_test = utest.drop([target_class], axis=1).values
    uy_test = utest[target_class].values
    
    ttdict = {
        'train': train,
        'test': test,
        'rtest': rtest,
        'ftest': ftest,
        'utest': utest,
        'X_test': X_test,
        'y_test': y_test,
        'rX_test': rX_test,
        'ry_test': ry_test,
        'fX_test': fX_test,
        'fy_test': fy_test,
        'uX_test': uX_test,
        'uy_test': uy_test,
    }

    return ttdict

def findFav(ttdict, pa, label):
    train = ttdict['train']

    pos_rates = [train[(train[pa] == u) & (train[label] == 1)].shape[0] / train[train[pa] == u].shape[0]
                 for u in train[pa].unique()]
    max_value = max(pos_rates)
    max_index = pos_rates.index(max_value)

    # Favoured group
    fav = train[pa].unique()[max_index]
    #print(fav)
    return fav

def fairCorrectPSP(df, pa, fav, d=0):
    from sklearn.naive_bayes import GaussianNB as nb
    import math
    
    df2 = df.copy()
    
    # Train NB model and get prediction confidence
    Xnb = df.drop("Target_encoded", axis = 1)
    ynb = df["Target_encoded"]
    
    model = nb()
    model.fit(Xnb, ynb)
    logProbs = model.predict_log_proba(Xnb)
    df2['pPos'] = [logProbs[i][1] for i in range(len(logProbs))]

    # subset favoured positive, favoured negative, unfavoured positive, unfavoured negative
    fav_pos = (df2[(df2[pa] == fav) & (df2["Target_encoded"] == 1)]
               .sort_values('pPos', ascending=True))
    #print(fav_pos)
    fav_neg = (df2[(df2[pa] == fav) & (df2["Target_encoded"] == 0)]
               .sort_values('pPos', ascending=False))
    #print(fav_neg)
    unfav_pos = (df2[(df2[pa] != fav) & (df2["Target_encoded"] == 1)]
                 .sort_values('pPos', ascending=True))
    #print(unfav_pos)
    unfav_neg = (df2[(df2[pa] != fav) & (df2["Target_encoded"] == 0)]
                 .sort_values('pPos', ascending=False))
    #print(unfav_neg)
    
    # drop aux columns
    fav_pos = fav_pos.drop(['pPos'], axis=1)
    fav_neg = fav_neg.drop(['pPos'], axis=1)
    unfav_pos = unfav_pos.drop(['pPos'], axis=1)
    unfav_neg = unfav_neg.drop(['pPos'], axis=1)
    
    if d < 1:

        # get favoured and unfavoured number of rows
        fav_size = fav_pos.shape[0] + fav_neg.shape[0]
        unfav_size = unfav_pos.shape[0] + unfav_neg.shape[0]

        # get positive ratios for favoured and unfavoured
        fav_pr = fav_pos.shape[0] / fav_size
        unfav_pr = unfav_pos.shape[0] / unfav_size

        #print(fav_pr)
        #print(unfav_pr)        
        pr = df[df['Target_encoded'] == 1].shape[0] / df.shape[0]

        # coefficients for fitting quad function
        a = ((fav_pr + unfav_pr) / 2) - pr
        b = (fav_pr - unfav_pr) / 2
        c = pr

        # corrected ratios
        corr_fpr = (a * (d ** 2)) + (b * d) + c
        corr_upr = (a * (d ** 2)) - (b * d) + c

        # number of elements to remove or add
        fav_move = math.floor((fav_pr - corr_fpr) * fav_size)
        unfav_move = math.floor((corr_upr - unfav_pr) * unfav_size)

        # elements to add
        ext_fn = pd.concat([fav_neg] * math.ceil(fav_move / fav_neg.shape[0]), ignore_index=True)
        ext_up = pd.concat([unfav_pos] * math.ceil(unfav_move / unfav_pos.shape[0]), ignore_index=True)
    
        # remove from fp and un
        fav_pos = fav_pos.tail(fav_pos.shape[0] - fav_move)
        unfav_neg = unfav_neg.tail(unfav_neg.shape[0] - unfav_move)
    
        # add to fn and up
        fav_neg = pd.concat([fav_neg, ext_fn.head(fav_move)], ignore_index=True) 
        unfav_pos = pd.concat([unfav_pos, ext_up.head(unfav_move)], ignore_index=True)
    
    # concatenate df's
    corr_dfs = [fav_pos, fav_neg, unfav_pos, unfav_neg]
    corr_df = pd.concat(corr_dfs)
    
    return corr_df

"""# Modelos e gráficos"""

def discriminationClassifier(df, predictions, att_sensitive, sensitive_label):
  df["predictions"] = predictions
  #print("Dentro do discriminationClassifier")
  #print(df)
  #calcula sempre para objetos preditos como 1
  df["predictions"] = df["predictions"].astype(str).astype(int)
  df[att_sensitive] = df[att_sensitive].astype(str).astype(int)
  details = df.apply(lambda x : True
              if x[att_sensitive] == sensitive_label  else False, axis = 1)
    
  #print(df[att_sensitive])
  #display(details)
  
  # Count number of True in the series
  num_rows = len(details[details == True].index)
  group = df[df[att_sensitive] == sensitive_label]
  #group["predictions"] = group["predictions"].astype(str).astype(int)

  group_positive = group.apply(lambda x : True
              if x["predictions"] == 1 else False, axis = 1) #>50k
  num_group_positive = len(group_positive[group_positive == True].index)
  positiveRate = num_group_positive/group.shape[0]
  return num_rows, positiveRate

def countElementsInBin(array, name):
  print(name)
  print(len(array))
  from00_01 = len(array[(array >= 0) & (array <= 0.1)])
  from01_02 = len(array[(array > 0.1) & (array <= 0.2)])
  from02_03 = len(array[(array > 0.2) & (array <= 0.3)])
  from03_04 = len(array[(array > 0.3) & (array <= 0.4)])
  from04_05 = len(array[(array > 0.4) & (array <= 0.5)])
  from05_06 = len(array[(array > 0.5) & (array <= 0.6)])
  from06_07 = len(array[(array > 0.6) & (array <= 0.7)])
  from07_08 = len(array[(array > 0.7) & (array <= 0.8)])
  from08_09 = len(array[(array > 0.8) & (array <= 0.9)])
  from09_1 = len(array[(array > 0.9) & (array <= 1)])
  print("0-0,1 = {}\n0,1-0,2 = {}\n0,2-0,3 = {}\n0,3-0,4 = {}\n0,4-0,5 = {}\n0,5-0,6 = {}\n0,6-0,7 = {}\n0,7-0,8 = {}\n0,8-0,9 = {}\n0,9-1 = {}\n".format(from00_01, from01_02, from02_03, from03_04, from04_05, from05_06, from06_07, from07_08, from08_09, from09_1))
  print(from00_01+ from01_02+ from02_03+ from03_04+ from04_05+ from05_06+ from06_07+ from07_08+ from08_09+ from09_1)

def criaModelos(df_list, X_test_target,  y_test, rstate):
  result_scores = []
  group_metrics = []
  disc_metrics = {}
  conf_matrix = {}
  matrix_df = {}
  nSplits = 2
  for df in df_list:
    #display(df)
    #print(df.name)
    
    y_train = df["Target_encoded"]
    X_train = df.drop("Target_encoded", axis = 1)
    
    X_test = X_test_target.drop("Target_encoded", axis = 1)

    discFolds = []
    i = 0
    x_t = X_test    

    fig = plt.figure(figsize=(10, 10))
    gs = GridSpec(5, 2)
    colors = plt.cm.get_cmap("Dark2")

    ax_calibration_curve = fig.add_subplot(gs[:2, :2])
    calibration_displays = {}

    # fit and apply the transform
    from imblearn.under_sampling import RandomUnderSampler
    undersample = RandomUnderSampler(sampling_strategy='majority')
    X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)

    for i, (clf, name) in enumerate(clf_list):
        clf.fit(X_train_under, y_train_under)
        displ = CalibrationDisplay.from_estimator(
            clf,
            X_test,
            y_test,
            n_bins=10,
            name=name,
            ax=ax_calibration_curve,
            color=colors(i),
          )
        calibration_displays[name] = displ

    ax_calibration_curve.grid()
    ax_calibration_curve.set_title("Calibração usando o " + df.name)

    # Add histogram
    test = []
    grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1), (4,0)]
    for i, (_, name) in enumerate(clf_list):
        row, col = grid_positions[i]
        ax = fig.add_subplot(gs[row, col])

        ax.hist(
            calibration_displays[name].y_prob,
            range=(0, 1),
            bins=10,
            label=name,
            color=colors(i),
        )
        ax.set(title=name, xlabel="Mean predicted probability", ylabel="Count")
        #countElementsInBin(calibration_displays[name].y_prob, name)

    plt.tight_layout()
    plt.savefig("grafico_"+str(i_tex)+"_"+df.name+".png")

    
    #print("\ny.prob = ")
    #print(test)
    #print("\n")
    #plt.show()    

      #calcula scores

    scores = defaultdict(list)
    groupsList = defaultdict(list)
      
    discClassifier = {}
    for i, (clf, name) in enumerate(clf_list):        
        
        clf.fit(X_train_under, y_train_under)
        y_prob = clf.predict_proba(X_test)
        y_pred = clf.predict(X_test)
        scores["Classifier"].append(name)
        groupsList["Classifier"].append(name)
        groupsList["Classifier"].append(name)

        total_w, positive_pred_w = discriminationClassifier(x_t, y_pred, "Sex_encoded", 1)
        total_b, positive_pred_b = discriminationClassifier(x_t, y_pred, "Sex_encoded", 0)

        if 'predicted' in X_test.columns:
          X_test = X_test.drop(columns=['predicted'])

        if 'true_class' in X_test.columns:
          X_test = X_test.drop(columns=['true_class'])

        if 'predictions' in X_test.columns:
          X_test = X_test.drop(columns=['predictions'])

        #print(X_test.columns)

        print("Discriminação do {} = {:+.3f}".format(name, positive_pred_w - positive_pred_b))
        discClassifier[name] = round(positive_pred_w - positive_pred_b, 3)
        b, w = accuracyByGroup(x_t, y_test, y_pred, "Sex_encoded", 0, 1)

        from sklearn.metrics import confusion_matrix
        matrix = confusion_matrix(y_test, y_pred)
        
        matrix_df[name]=matrix.diagonal()/matrix.sum(axis=1)
        print(matrix_df[name])
        #print(matrix.diagonal()/matrix.sum(axis=1))
        conf_matrix[df.name] = matrix_df[name]

        metric_group = ["Grupo", "Acurácia Classe positiva", "Acurácia classe negativa", "VN ", "VP + VN ", "Acurácia"]

        for i in range(len(metric_group)):
          groupsList[metric_group[i]].append(b[i])
          groupsList[metric_group[i]].append(w[i])

        for metric in [brier_score_loss, log_loss]:
            score_name = metric.__name__.replace("_", " ").replace("score", "").capitalize()
            scores[score_name].append(round(metric(y_test, y_prob[:, 1]),3))

        for metric in [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]:
            score_name = metric.__name__.replace("_", " ").replace("score", "").capitalize()
            scores[score_name].append(round(metric(y_test, y_pred),3))
        #print(groupsList)
        df_group = pd.DataFrame(groupsList).set_index("Classifier")
        score_df = pd.DataFrame(scores).set_index("Classifier")
        df_group.name = df.name
        score_df.name = df.name
        score_df["Conjunto de dados"] = df.name
        df_group["Conjunto de dados"] = df.name

    discFolds.append(discClassifier)
    i = i + 1
    disc_metrics[df.name] = discFolds
    group_metrics.append(df_group)
    result_scores.append(score_df)
  print(conf_matrix)
    
  return result_scores, group_metrics, disc_metrics, conf_matrix

"""# Criando os folds"""

def reportFairness(dfs, X_test,  y_test, state, i_tex):
  scores, groups, discs, conf_matrix = criaModelos(dfs, X_test, y_test, state)

  for score in scores:
    #print("\n\nScore")
    #print(score.name)  
    #display(score)
    latexName = score.name + " " + str(i_tex) + ".tex"
    score.to_latex(latexName, caption=score.name, label = score.name+" "+str(i_tex))
    i_tex = i_tex + 1 

  for group in groups:
    #print("\n\n")
    #print(group.name)  
    #display(group)
    latexName = group.name + " " + str(i_tex) + ".tex"
    group.to_latex(latexName, caption=group.name, label = group.name+" "+str(i_tex))
    i_tex = i_tex + 1 

  for key in discs.keys():
    mini = pd.DataFrame.from_dict(discs[key])
    mini.name = "Discriminação " +key
    mini.index.name = "Fold"
    #print("\n\n")
    print("Discriminação do " + key)
    #display(mini)
    latexName = mini.name + " " + str(i_tex) + ".tex"
    mini.to_latex(latexName, caption=mini.name, label = mini.name+" "+str(i_tex))
    i_tex = i_tex + 1
    
  return scores, groups, discs, conf_matrix

def aplicaMassageamento(df):
  #print("\nMassageamento\n")
  promo, demo = ranker(df, 'Sex_encoded', 1)
  promo = promo.sort_values(by=['predict_proba'], ascending=False) #decrescente
  demo = demo.sort_values(by=['predict_proba']) #ascendente

  print("\nCalculando a Discriminação antes do Massageamento\n")
 
  m, discriminationDataset = massageChanges(df, 'Sex_encoded', 0, 1, 'Target_encoded', 1)
  print(discriminationDataset)
  #print("Quantidade de trocas a serem realizadas pela técnica de Massageamento: {}".format(ceil(m)))
  

  
  #Alterando a classe dos "m" primeiros objetos de "promo" e "demo"
  m = ceil(m)

  new_promo = promo.head(m)

  new_promo["true_class"].replace({0: 1}, inplace=True)

  new_demo = demo.head(m)

  new_demo["true_class"].replace({1: 0}, inplace=True)

  new_promo = new_promo.drop("predict_proba", axis = 1)
  new_demo = new_demo.drop("predict_proba", axis = 1)

  new_promo = new_promo.rename(columns={"true_class": "Target_encoded"})
  new_demo = new_demo.rename(columns={"true_class": "Target_encoded"})

  new_promo = new_promo.sort_index()
  new_demo = new_demo.sort_index()

  index = new_promo.index

  adult_df_numerical_massage = df.select_dtypes(exclude='object')
  
  #print("\n\nnew promo index = {}\n\n".format(new_promo.index))
  adult_df_numerical_massage.name = "Conjunto de dados Massageado"
  #display(adult_df_numerical_massage)

  for x in new_promo.index:
    #print(x)
    adult_df_numerical_massage.at[x, 'Target_encoded']= 1
    #adult_df_numerical_massage.iloc[x, 13] = 1

  for x in new_demo.index:
    #print(x)
    adult_df_numerical_massage.at[x, 'Target_encoded']= 0

  #recalculando a discriminação
  #print("Discriminação depois de aplicado o massageamento:")
  m, discriminationDataset = massageChanges(adult_df_numerical_massage, 'Sex_encoded', 0, 1, 'Target_encoded', 1)
  #print(discriminationDataset)
  #print("Quantidade de trocas a serem realizadas pela técnica de Massageamento: {}".format(ceil(m)))
  

  return adult_df_numerical_massage

def aplicaAmostraPref(df):
  #print("\nAmostragem Preferencial")
  ttdict = ttSplit(df, 'Sex_encoded', 'Target_encoded')

  fav = findFav(ttdict, 'Sex_encoded', 'Target_encoded')

  dfPSP = fairCorrectPSP(df, 'Sex_encoded', fav)
  dfPSP.name = "Conjunto de dados aplicado o Preferential Sampling"

  #Verificando a propoção de homens e mulheres classificados como '>50k'

  menPSP, men_positive_rate_PSP = calcProportionPositive(dfPSP, 'Sex_encoded', 1, 'Target_encoded', 1)

  womenPSP, women_positive_rate_PSP = calcProportionPositive(dfPSP, 'Sex_encoded', 0, 'Target_encoded', 1)

  #print("\nVerificando a propoção de homens e mulheres classificados como '>50k'\n")

  #print(menPSP, men_positive_rate_PSP, womenPSP, women_positive_rate_PSP)

  return dfPSP

def calcMediaDesvClassificador(full_report, classificador, conjunto):

    classificador_full_report = full_report.filter(like=classificador, axis=0)

    classificador_full_report_bruto = classificador_full_report.loc[
        classificador_full_report['Conjunto de dados'] == conjunto]

    classificador_full_report_bruto = classificador_full_report_bruto.drop(
        'Conjunto de dados', axis=1)

    classificador_full_report_bruto_folds = pd.DataFrame(data=None)
    for column in classificador_full_report_bruto:
        meanC = classificador_full_report_bruto[column].mean()
        stdC = classificador_full_report_bruto[column].std()
        classificador_full_report_bruto_folds.at[0, column] = meanC
        classificador_full_report_bruto_folds.at[1, column] = stdC
        classificador_full_report_bruto_folds = classificador_full_report_bruto_folds.reset_index(
            drop=True)

    classificador_full_report_bruto_folds['Conjunto de dados'] = conjunto
    classificador_full_report_bruto_folds.rename(index={
        0: 'Média dos Folds',
        1: 'Desv. Padrão'
    },
                                                 inplace=True)

    return classificador_full_report_bruto_folds

def calcMediaDesvClassificadorGrupos(full_report, classificador, conjunto, grupo):
    #import ipdb; ipdb.set_trace()

    classificador_full_report = full_report.filter(like=classificador, axis=0)

    classificador_full_report_conjunto = classificador_full_report.loc[
        classificador_full_report['Conjunto de dados'] == conjunto]
    
    classificador_full_report_conjunto_grupo = classificador_full_report_conjunto.loc[
        classificador_full_report_conjunto['Grupo'] == grupo]

    classificador_full_report_conjunto_grupo = classificador_full_report_conjunto_grupo.drop(
        ['Grupo', 'Conjunto de dados'], axis=1)

    classificador_full_report_bruto_folds = pd.DataFrame(data=None)
    for column in classificador_full_report_conjunto_grupo:
        meanC = classificador_full_report_conjunto_grupo[column].mean()
        stdC = classificador_full_report_conjunto_grupo[column].std()
        classificador_full_report_bruto_folds.at[0, column] = meanC
        classificador_full_report_bruto_folds.at[1, column] = stdC
        classificador_full_report_bruto_folds = classificador_full_report_bruto_folds.reset_index(
            drop=True)

    classificador_full_report_bruto_folds['Conjunto de dados'] = conjunto
    classificador_full_report_bruto_folds['Grupo'] = grupo
    classificador_full_report_bruto_folds.rename(index={
        0: 'Média dos Folds',
        1: 'Desv. Padrão'
    },
                                                 inplace=True)

    return classificador_full_report_bruto_folds

def calcMediaDesvDiscriminacao(full_report, conjunto):
  discriminacao_full_report_folds = pd.DataFrame(data=None)
  for column in full_report:
    meanC = full_report[column].mean()
    stdC = full_report[column].std()
    discriminacao_full_report_folds.at[0, column] = meanC
    discriminacao_full_report_folds.at[1, column] = stdC
    discriminacao_full_report_folds = discriminacao_full_report_folds.reset_index(
              drop=True)

  discriminacao_full_report_folds['Conjunto de dados'] = conjunto
  discriminacao_full_report_folds.rename(index={
        0: 'Média dos Folds',
        1: 'Desv. Padrão'
    },
                                                 inplace=True)

  return discriminacao_full_report_folds

x = german_df.drop("Target_encoded", axis = 1)
y = german_df["Target_encoded"]

skf = StratifiedKFold(10, random_state= 42, shuffle=True)
skf.get_n_splits(x, y)

scores_full_report = pd.DataFrame(data=None)
groups_full_report = pd.DataFrame(data=None)

for train_index, test_index in skf.split(x, y):
      X_train, X_test = x.loc[x.index.intersection(train_index)], x.loc[x.index.intersection(test_index)]
      y_train, y_test = y.loc[y.index.intersection(train_index)], y.loc[y.index.intersection(test_index)]

      X_train['Target_encoded'] = y_train #>50k ou #<=50k
      X_test['Target_encoded'] = y_test

      #display(X_train)
      #display(X_test)

      encoded_x_train, encoded_x_test, encoded_y_train, encoded_y_test = encodeR(X_train, X_test)
      #display(encoded_x_train)      
      #display(encoded_x_test)

      #Quantos homens estão no fold, e desses quantos tem renda >50k?
      men, men_positive_rate = calcProportionPositive(encoded_x_train, 'Sex_encoded', 1, 'Target_encoded', 1)

      #Quantas mulheres existem no fold antes da redução de features, e quantas delas tem renda >50k?
      women, women_positive_rate = calcProportionPositive(encoded_x_train, 'Sex_encoded', 0, 'Target_encoded', 1)
      
      print("Atributo = gender\tGrupo favorecido = men\tGrupo desfavorecido = women\n\n")
      print("grupo desfavorecido positivo / grupo favorecido positivo = {}\n".format(women_positive_rate/men_positive_rate))
      print("grupo favorecido positivo - grupo desfavorecido positivo = {}\n".format(men_positive_rate - women_positive_rate))


      #print("\nAplicando pré processamento\n")
      encoded_x_train_massageado = aplicaMassageamento(encoded_x_train) #retornar o y_train do massageamento e da amostragem preferencial
      encoded_x_train_massageado.name = "Aplicado massageamento"
      encoded_x_train_amostraPref = aplicaAmostraPref(encoded_x_train) #retornar o y_train do massageamento e da amostragem preferencial
      encoded_x_train_amostraPref.name = "Aplicado Amostragem pref"
      encoded_x_train.name = "Conjunto bruto"

      dfs = [encoded_x_train, encoded_x_train_massageado, encoded_x_train_amostraPref]

      scores, groups, discs, conf_matrix = reportFairness(dfs, encoded_x_test, encoded_y_test, 42, i_tex)    

      temp = pd.concat(scores)
      temp2 = pd.concat(groups)  
      
      scores_full_report = scores_full_report.append(temp, ignore_index=False)
      groups_full_report = groups_full_report.append(temp2, ignore_index=False)
      #print(discs)
      
      #scores_full_report = scores_full_report.dropna()
      logistic_full_report_bruto = calcMediaDesvClassificador(
        scores_full_report, 'Logistic', 'Conjunto bruto')

      logistic_full_report_massageado = calcMediaDesvClassificador(
        scores_full_report, 'Logistic', 'Aplicado massageamento')

      logistic_full_report_amostrapref = calcMediaDesvClassificador(
        scores_full_report, 'Logistic', 'Aplicado Amostragem pref')

      #grupos

      logistic_full_report_bruto_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Logistic', 'Conjunto bruto', 'Favorecido')

      logistic_full_report_bruto_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Logistic', 'Conjunto bruto', 'Desfavorecido')

      logistic_full_report_massageado_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Logistic', 'Aplicado massageamento', 'Favorecido')

      logistic_full_report_massageado_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Logistic', 'Aplicado massageamento', 'Desfavorecido')

      logistic_full_report_amostrapref_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Logistic', 'Aplicado Amostragem pref', 'Favorecido')

      logistic_full_report_amostrapref_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Logistic', 'Aplicado Amostragem pref', 'Desfavorecido')
      
      #Naive Bayes
      nb_full_report_bruto = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes', 'Conjunto bruto')
      
      nb_full_report_massageado = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes', 'Aplicado massageamento')
      
      nb_full_report_amostrapref = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes', 'Aplicado Amostragem pref')

      #grupos

      nb_full_report_bruto_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes', 'Conjunto bruto', 'Favorecido')

      nb_full_report_bruto_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes', 'Conjunto bruto', 'Desfavorecido')

      nb_full_report_massageado_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes', 'Aplicado massageamento', 'Favorecido')

      nb_full_report_massageado_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes', 'Aplicado massageamento', 'Desfavorecido')

      nb_full_report_amostrapref_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes', 'Aplicado Amostragem pref', 'Favorecido')

      nb_full_report_amostrapref_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes', 'Aplicado Amostragem pref', 'Desfavorecido')
      
      #Naive Bayes + Isotonic

      nbiso_full_report_bruto = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes + Isotonic', 'Conjunto bruto')
      
      nbiso_full_report_massageado = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes + Isotonic', 'Aplicado massageamento')
      
      nbiso_full_report_amostrapref = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes + Isotonic', 'Aplicado Amostragem pref')

      #grupos

      nbiso_full_report_bruto_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Isotonic', 'Conjunto bruto', 'Favorecido')

      nbiso_full_report_bruto_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Isotonic', 'Conjunto bruto', 'Desfavorecido')

      nbiso_full_report_massageado_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Isotonic', 'Aplicado massageamento', 'Favorecido')

      nbiso_full_report_massageado_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Isotonic', 'Aplicado massageamento', 'Desfavorecido')

      nbiso_full_report_amostrapref_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Isotonic', 'Aplicado Amostragem pref', 'Favorecido')

      nbiso_full_report_amostrapref_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Isotonic', 'Aplicado Amostragem pref', 'Desfavorecido')


      #Naive Bayes + Sigmoid

      nbsig_full_report_bruto = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes + Sigmoid', 'Conjunto bruto')
      
      nbsig_full_report_massageado = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes + Sigmoid', 'Aplicado massageamento')
      
      nbsig_full_report_amostrapref = calcMediaDesvClassificador(
        scores_full_report, 'Naive Bayes + Sigmoid', 'Aplicado Amostragem pref')
      
      #grupos

      nbsig_full_report_bruto_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Sigmoid', 'Conjunto bruto', 'Favorecido')

      nbsig_full_report_bruto_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Sigmoid', 'Conjunto bruto', 'Desfavorecido')

      nbsig_full_report_massageado_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Sigmoid', 'Aplicado massageamento', 'Favorecido')

      nbsig_full_report_massageado_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Sigmoid', 'Aplicado massageamento', 'Desfavorecido')

      nbsig_full_report_amostrapref_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Sigmoid', 'Aplicado Amostragem pref', 'Favorecido')

      nbsig_full_report_amostrapref_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Naive Bayes + Sigmoid', 'Aplicado Amostragem pref', 'Desfavorecido')
      

      #Decision Tree Classifier

      arvore_full_report_bruto = calcMediaDesvClassificador(
        scores_full_report, 'Decision Tree Classifier', 'Conjunto bruto')
      
      arvore_full_report_massageado = calcMediaDesvClassificador(
        scores_full_report, 'Decision Tree Classifier', 'Aplicado massageamento')
      
      arvore_full_report_amostrapref = calcMediaDesvClassificador(
        scores_full_report, 'Decision Tree Classifier', 'Aplicado Amostragem pref')
      
      #grupos

      arvore_full_report_bruto_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Decision Tree Classifier', 'Conjunto bruto', 'Favorecido')

      arvore_full_report_bruto_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Decision Tree Classifier', 'Conjunto bruto', 'Desfavorecido')

      arvore_full_report_massageado_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Decision Tree Classifier', 'Aplicado massageamento', 'Favorecido')

      arvore_full_report_massageado_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Decision Tree Classifier', 'Aplicado massageamento', 'Desfavorecido')

      arvore_full_report_amostrapref_favorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Decision Tree Classifier', 'Aplicado Amostragem pref', 'Favorecido')

      arvore_full_report_amostrapref_desfavorecido = calcMediaDesvClassificadorGrupos(
        groups_full_report, 'Decision Tree Classifier', 'Aplicado Amostragem pref', 'Desfavorecido')
      


latexName = "logistic_full_report_bruto.tex"
logistic_full_report_bruto.to_latex(latexName, caption="logistic_full_report_bruto.tex", label = "logistic_full_report_bruto.tex")

latexName = "logistic_full_report_massageado.tex"
logistic_full_report_massageado.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "logistic_full_report_amostrapref.tex"
logistic_full_report_amostrapref.to_latex(latexName, caption=latexName, label = latexName)

#grupos

latexName = "logistic_full_report_bruto_favorecido.tex"
logistic_full_report_bruto_favorecido.to_latex(latexName, caption="logistic_full_report_bruto_favorecido.tex", label = "logistic_full_report_bruto_favorecido.tex")

latexName = "logistic_full_report_bruto_desfavorecido.tex"
logistic_full_report_bruto_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "logistic_full_report_massageado_favorecido.tex"
logistic_full_report_massageado_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "logistic_full_report_massageado_desfavorecido.tex"
logistic_full_report_massageado_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "logistic_full_report_amostrapref_favorecido.tex"
logistic_full_report_amostrapref_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "logistic_full_report_amostrapref_desfavorecido.tex"
logistic_full_report_amostrapref_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)






latexName = "nb_full_report_bruto.tex"
nb_full_report_bruto.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nb_full_report_massageado.tex"
nb_full_report_massageado.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "nb_full_report_amostrapref.tex"
nb_full_report_amostrapref.to_latex(latexName, caption=latexName, label = latexName)

#grupos

latexName = "nb_full_report_bruto_favorecido.tex"
nb_full_report_bruto_favorecido.to_latex(latexName, caption="nb_full_report_bruto_favorecido.tex", label = "nb_full_report_bruto_favorecido.tex")

latexName = "nb_full_report_bruto_desfavorecido.tex"
nb_full_report_bruto_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "nb_full_report_massageado_favorecido.tex"
nb_full_report_massageado_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nb_full_report_massageado_desfavorecido.tex"
nb_full_report_massageado_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nb_full_report_amostrapref_favorecido.tex"
nb_full_report_amostrapref_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nb_full_report_amostrapref_desfavorecido.tex"
nb_full_report_amostrapref_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)






latexName = "nbiso_full_report_bruto.tex"
nbiso_full_report_bruto.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbiso_full_report_massageado.tex"
nbiso_full_report_massageado.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "nbiso_full_report_amostrapref.tex"
nbiso_full_report_amostrapref.to_latex(latexName, caption=latexName, label = latexName)

#grupos

latexName = "nbiso_full_report_bruto_favorecido.tex"
nbiso_full_report_bruto_favorecido.to_latex(latexName, caption="nbiso_full_report_bruto_favorecido.tex", label = "nbiso_full_report_bruto_favorecido.tex")

latexName = "nbiso_full_report_bruto_desfavorecido.tex"
nbiso_full_report_bruto_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "nbiso_full_report_massageado_favorecido.tex"
nbiso_full_report_massageado_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbiso_full_report_massageado_desfavorecido.tex"
nbiso_full_report_massageado_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbiso_full_report_amostrapref_favorecido.tex"
nbiso_full_report_amostrapref_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbiso_full_report_amostrapref_desfavorecido.tex"
nbiso_full_report_amostrapref_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)






latexName = "nbsig_full_report_bruto.tex"
nbsig_full_report_bruto.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbsig_full_report_massageado.tex"
nbsig_full_report_massageado.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "nbsig_full_report_amostrapref.tex"
nbsig_full_report_amostrapref.to_latex(latexName, caption=latexName, label = latexName)

#grupos

latexName = "nbsig_full_report_bruto_favorecido.tex"
nbsig_full_report_bruto_favorecido.to_latex(latexName, caption="nbsig_full_report_bruto_favorecido.tex", label = "nbsig_full_report_bruto_favorecido.tex")

latexName = "nbsig_full_report_bruto_desfavorecido.tex"
nbsig_full_report_bruto_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "nbsig_full_report_massageado_favorecido.tex"
nbsig_full_report_massageado_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbsig_full_report_massageado_desfavorecido.tex"
nbsig_full_report_massageado_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbsig_full_report_amostrapref_favorecido.tex"
nbsig_full_report_amostrapref_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "nbsig_full_report_amostrapref_desfavorecido.tex"
nbsig_full_report_amostrapref_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)




latexName = "arvore_full_report_bruto.tex"
arvore_full_report_bruto.to_latex(latexName, caption="logistic_full_report_bruto.tex", label = "logistic_full_report_bruto.tex")

latexName = "arvore_full_report_massageado.tex"
arvore_full_report_massageado.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "arvore_full_report_amostrapref.tex"
arvore_full_report_amostrapref.to_latex(latexName, caption=latexName, label = latexName)

#grupos
latexName = "arvore_full_report_bruto_favorecido.tex"
arvore_full_report_bruto_favorecido.to_latex(latexName, caption="arvore_full_report_bruto_favorecido.tex", label = "arvore_full_report_bruto_favorecido.tex")

latexName = "arvore_full_report_bruto_desfavorecido.tex"
arvore_full_report_bruto_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)
      
latexName = "arvore_full_report_massageado_favorecido.tex"
arvore_full_report_massageado_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "arvore_full_report_massageado_desfavorecido.tex"
arvore_full_report_massageado_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "arvore_full_report_amostrapref_favorecido.tex"
arvore_full_report_amostrapref_favorecido.to_latex(latexName, caption=latexName, label = latexName)

latexName = "arvore_full_report_amostrapref_desfavorecido.tex"
arvore_full_report_amostrapref_desfavorecido.to_latex(latexName, caption=latexName, label = latexName)


#display(logistic_full_report_bruto)
#display(logistic_full_report_massageado)
#display(logistic_full_report_amostrapref)

#display(arvore_full_report_amostrapref)